#!/usr/bin/env python3
"""
Gemini LLMå®¢æˆ·ç«¯ - å¯¹æ¥Google Gemini API
"""

import requests
import json
import time
from typing import Optional, Dict, Any, List
from dataclasses import dataclass


@dataclass
class GeminiResponse:
    """Geminiå“åº”æ•°æ®ç±»"""
    text: str
    usage_metadata: Optional[Dict[str, Any]] = None
    finish_reason: Optional[str] = None
    error: Optional[str] = None


class GeminiClient:
    """Gemini LLMå®¢æˆ·ç«¯ç±»"""
    
    def __init__(self, api_key: str, model: str = "gemini-1.5-flash", config=None):
        """
        åˆå§‹åŒ–Geminiå®¢æˆ·ç«¯
        
        Args:
            api_key: Gemini APIå¯†é’¥
            model: ä½¿ç”¨çš„æ¨¡å‹åç§°
            config: é…ç½®ç®¡ç†å™¨å®ä¾‹
        """
        self.api_key = api_key
        self.model = model
        self.config = config
        
        # APIç«¯ç‚¹
        self.base_url = "https://generativelanguage.googleapis.com/v1beta"
        
        # è¯·æ±‚é…ç½®
        self.timeout = 30
        self.max_retries = 3
        self.retry_delay = 1.0
        
        # æ¨¡å‹å‚æ•°
        self.generation_config = {
            "temperature": 0.7,
            "top_p": 0.8,
            "top_k": 40,
            "max_output_tokens": 2048,
        }
        
        print(f"âœ… Geminiå®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆ (æ¨¡å‹: {self.model})")
    
    def _make_request(self, endpoint: str, data: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """
        å‘é€HTTPè¯·æ±‚åˆ°Gemini API
        
        Args:
            endpoint: APIç«¯ç‚¹
            data: è¯·æ±‚æ•°æ®
            
        Returns:
            APIå“åº”æ•°æ®æˆ–None
        """
        url = f"{self.base_url}/{endpoint}?key={self.api_key}"
        headers = {
            "Content-Type": "application/json"
        }
        
        for attempt in range(self.max_retries):
            try:
                print(f"ğŸŒ å‘é€è¯·æ±‚åˆ°Gemini API (å°è¯• {attempt + 1}/{self.max_retries})")
                
                response = requests.post(
                    url,
                    headers=headers,
                    json=data,
                    timeout=self.timeout
                )
                
                if response.status_code == 200:
                    return response.json()
                elif response.status_code == 429:
                    # é€Ÿç‡é™åˆ¶ï¼Œç­‰å¾…åé‡è¯•
                    wait_time = self.retry_delay * (2 ** attempt)
                    print(f"âš ï¸ è¯·æ±‚é¢‘ç‡é™åˆ¶ï¼Œç­‰å¾… {wait_time:.1f} ç§’åé‡è¯•...")
                    time.sleep(wait_time)
                    continue
                elif response.status_code == 400:
                    try:
                        error_data = response.json()
                        error_msg = error_data.get('error', {}).get('message', 'æœªçŸ¥é”™è¯¯')
                        print(f"âŒ è¯·æ±‚å‚æ•°é”™è¯¯: {error_msg}")
                        return {"error": f"è¯·æ±‚å‚æ•°é”™è¯¯: {error_msg}"}
                    except:
                        print(f"âŒ è¯·æ±‚å‚æ•°é”™è¯¯: {response.text}")
                        return {"error": f"è¯·æ±‚å‚æ•°é”™è¯¯: {response.status_code}"}
                elif response.status_code == 403:
                    print("âŒ APIå¯†é’¥æ— æ•ˆæˆ–æƒé™ä¸è¶³")
                    return {"error": "APIå¯†é’¥æ— æ•ˆæˆ–æƒé™ä¸è¶³"}
                else:
                    print(f"âŒ APIè¯·æ±‚å¤±è´¥: HTTP {response.status_code}")
                    if attempt < self.max_retries - 1:
                        time.sleep(self.retry_delay)
                        continue
                    return {"error": f"APIè¯·æ±‚å¤±è´¥: HTTP {response.status_code}"}
                    
            except requests.exceptions.Timeout:
                print(f"â±ï¸ è¯·æ±‚è¶…æ—¶ (å°è¯• {attempt + 1}/{self.max_retries})")
                if attempt < self.max_retries - 1:
                    time.sleep(self.retry_delay)
                    continue
                return {"error": "è¯·æ±‚è¶…æ—¶"}
                
            except requests.exceptions.ConnectionError:
                print(f"ğŸŒ ç½‘ç»œè¿æ¥é”™è¯¯ (å°è¯• {attempt + 1}/{self.max_retries})")
                if attempt < self.max_retries - 1:
                    time.sleep(self.retry_delay * 2)  # è¿æ¥é”™è¯¯ç­‰å¾…æ›´ä¹…
                    continue
                return {"error": "ç½‘ç»œè¿æ¥é”™è¯¯"}
                
            except Exception as e:
                print(f"âŒ è¯·æ±‚å¼‚å¸¸: {e}")
                if attempt < self.max_retries - 1:
                    time.sleep(self.retry_delay)
                    continue
                return {"error": f"è¯·æ±‚å¼‚å¸¸: {str(e)}"}
        
        return {"error": "æ‰€æœ‰é‡è¯•å‡å¤±è´¥"}
    
    def generate_content(self, prompt: str, system_prompt: Optional[str] = None) -> GeminiResponse:
        """
        ç”Ÿæˆå†…å®¹
        
        Args:
            prompt: ç”¨æˆ·è¾“å…¥çš„æç¤ºè¯
            system_prompt: ç³»ç»Ÿæç¤ºè¯ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            GeminiResponseå¯¹è±¡
        """
        try:
            print(f"ğŸ¤– å¤„ç†Geminiè¯·æ±‚: {prompt[:50]}...")
            
            # æ„å»ºæ¶ˆæ¯å†…å®¹
            contents = []
            
            # å¦‚æœæœ‰ç³»ç»Ÿæç¤ºè¯ï¼Œå…ˆæ·»åŠ 
            if system_prompt:
                contents.append({
                    "role": "user",
                    "parts": [{"text": f"System: {system_prompt}"}]
                })
            
            # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
            contents.append({
                "role": "user", 
                "parts": [{"text": prompt}]
            })
            
            # æ„å»ºè¯·æ±‚æ•°æ®
            request_data = {
                "contents": contents,
                "generationConfig": self.generation_config,
                "safetySettings": [
                    {
                        "category": "HARM_CATEGORY_HARASSMENT",
                        "threshold": "BLOCK_MEDIUM_AND_ABOVE"
                    },
                    {
                        "category": "HARM_CATEGORY_HATE_SPEECH",
                        "threshold": "BLOCK_MEDIUM_AND_ABOVE"
                    },
                    {
                        "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
                        "threshold": "BLOCK_MEDIUM_AND_ABOVE"
                    },
                    {
                        "category": "HARM_CATEGORY_DANGEROUS_CONTENT",
                        "threshold": "BLOCK_MEDIUM_AND_ABOVE"
                    }
                ]
            }
            
            # å‘é€è¯·æ±‚
            endpoint = f"models/{self.model}:generateContent"
            response_data = self._make_request(endpoint, request_data)
            
            if not response_data:
                return GeminiResponse(
                    text="",
                    error="æ— æ³•è¿æ¥åˆ°Gemini API"
                )
            
            # æ£€æŸ¥é”™è¯¯
            if "error" in response_data:
                return GeminiResponse(
                    text="",
                    error=response_data["error"]
                )
            
            # è§£æå“åº”
            candidates = response_data.get("candidates", [])
            if not candidates:
                return GeminiResponse(
                    text="",
                    error="APIè¿”å›ç©ºå“åº”"
                )
            
            candidate = candidates[0]
            
            # æ£€æŸ¥å®ŒæˆåŸå› 
            finish_reason = candidate.get("finishReason", "")
            if finish_reason == "SAFETY":
                return GeminiResponse(
                    text="",
                    error="å†…å®¹è¢«å®‰å…¨è¿‡æ»¤å™¨é˜»æ­¢",
                    finish_reason=finish_reason
                )
            elif finish_reason == "RECITATION":
                return GeminiResponse(
                    text="",
                    error="å†…å®¹å¯èƒ½æ¶‰åŠç‰ˆæƒé—®é¢˜",
                    finish_reason=finish_reason
                )
            
            # æå–æ–‡æœ¬å†…å®¹
            content = candidate.get("content", {})
            parts = content.get("parts", [])
            
            if not parts:
                return GeminiResponse(
                    text="",
                    error="å“åº”ä¸­æ²¡æœ‰æ‰¾åˆ°æ–‡æœ¬å†…å®¹"
                )
            
            # åˆå¹¶æ‰€æœ‰æ–‡æœ¬éƒ¨åˆ†
            text_parts = []
            for part in parts:
                if "text" in part:
                    text_parts.append(part["text"])
            
            response_text = "".join(text_parts).strip()
            
            # æå–ä½¿ç”¨æƒ…å†µå…ƒæ•°æ®
            usage_metadata = response_data.get("usageMetadata", {})
            
            print(f"âœ… Geminiå“åº”æˆåŠŸï¼Œæ–‡æœ¬é•¿åº¦: {len(response_text)}")
            
            return GeminiResponse(
                text=response_text,
                usage_metadata=usage_metadata,
                finish_reason=finish_reason
            )
            
        except Exception as e:
            print(f"âŒ Geminiå†…å®¹ç”Ÿæˆå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return GeminiResponse(
                text="",
                error=f"å†…å®¹ç”Ÿæˆå¼‚å¸¸: {str(e)}"
            )
    
    def chat(self, message: str, conversation_history: Optional[List[Dict[str, str]]] = None) -> GeminiResponse:
        """
        è¿›è¡Œå¯¹è¯
        
        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
            conversation_history: å¯¹è¯å†å² [{"role": "user/model", "text": "..."}]
            
        Returns:
            GeminiResponseå¯¹è±¡
        """
        try:
            print(f"ğŸ’¬ å¤„ç†å¯¹è¯è¯·æ±‚: {message[:50]}...")
            
            # æ„å»ºå¯¹è¯å†…å®¹
            contents = []
            
            # æ·»åŠ å†å²å¯¹è¯
            if conversation_history:
                for msg in conversation_history:
                    role = msg["role"]
                    # Gemini APIä¸­åŠ©æ‰‹è§’è‰²æ˜¯"model"
                    if role == "assistant":
                        role = "model"
                    
                    contents.append({
                        "role": role,
                        "parts": [{"text": msg["text"]}]
                    })
            
            # æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
            contents.append({
                "role": "user",
                "parts": [{"text": message}]
            })
            
            # æ„å»ºè¯·æ±‚æ•°æ®
            request_data = {
                "contents": contents,
                "generationConfig": self.generation_config
            }
            
            # å‘é€è¯·æ±‚
            endpoint = f"models/{self.model}:generateContent"
            response_data = self._make_request(endpoint, request_data)
            
            if not response_data:
                return GeminiResponse(
                    text="",
                    error="æ— æ³•è¿æ¥åˆ°Gemini API"
                )
            
            # æ£€æŸ¥é”™è¯¯
            if "error" in response_data:
                return GeminiResponse(
                    text="",
                    error=response_data["error"]
                )
            
            # è§£æå“åº”ï¼ˆä¸generate_contentç›¸åŒçš„é€»è¾‘ï¼‰
            candidates = response_data.get("candidates", [])
            if not candidates:
                return GeminiResponse(
                    text="",
                    error="APIè¿”å›ç©ºå“åº”"
                )
            
            candidate = candidates[0]
            content = candidate.get("content", {})
            parts = content.get("parts", [])
            
            if not parts:
                return GeminiResponse(
                    text="",
                    error="å“åº”ä¸­æ²¡æœ‰æ‰¾åˆ°æ–‡æœ¬å†…å®¹"
                )
            
            # åˆå¹¶æ–‡æœ¬å†…å®¹
            text_parts = [part["text"] for part in parts if "text" in part]
            response_text = "".join(text_parts).strip()
            
            # æå–å…ƒæ•°æ®
            usage_metadata = response_data.get("usageMetadata", {})
            finish_reason = candidate.get("finishReason", "")
            
            print(f"âœ… å¯¹è¯å“åº”æˆåŠŸï¼Œæ–‡æœ¬é•¿åº¦: {len(response_text)}")
            
            return GeminiResponse(
                text=response_text,
                usage_metadata=usage_metadata,
                finish_reason=finish_reason
            )
            
        except Exception as e:
            print(f"âŒ å¯¹è¯å¤„ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return GeminiResponse(
                text="",
                error=f"å¯¹è¯å¤„ç†å¼‚å¸¸: {str(e)}"
            )
    
    def set_generation_config(self, **kwargs):
        """
        è®¾ç½®ç”Ÿæˆé…ç½®
        
        Args:
            temperature: æ¸©åº¦å‚æ•° (0.0-1.0)
            top_p: Top-på‚æ•° (0.0-1.0)  
            top_k: Top-kå‚æ•°
            max_output_tokens: æœ€å¤§è¾“å‡ºé•¿åº¦
        """
        for key, value in kwargs.items():
            if key in self.generation_config:
                self.generation_config[key] = value
                print(f"ğŸ”§ æ›´æ–°ç”Ÿæˆå‚æ•°: {key} = {value}")
    
    def test_connection(self) -> bool:
        """
        æµ‹è¯•APIè¿æ¥
        
        Returns:
            è¿æ¥æ˜¯å¦æˆåŠŸ
        """
        try:
            print("ğŸ” æµ‹è¯•Gemini APIè¿æ¥...")
            
            test_prompt = "è¯·ç®€å•å›ç­”ï¼šä½ å¥½"
            response = self.generate_content(test_prompt)
            
            if response.error:
                print(f"âŒ è¿æ¥æµ‹è¯•å¤±è´¥: {response.error}")
                return False
            
            if response.text:
                print(f"âœ… è¿æ¥æµ‹è¯•æˆåŠŸï¼Œå“åº”: {response.text[:50]}...")
                return True
            else:
                print("âŒ è¿æ¥æµ‹è¯•å¤±è´¥: ç©ºå“åº”")
                return False
                
        except Exception as e:
            print(f"âŒ è¿æ¥æµ‹è¯•å¼‚å¸¸: {e}")
            return False